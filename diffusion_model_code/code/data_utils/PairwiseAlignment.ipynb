{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0c4d14-cb61-4ad4-bb23-e528e54fd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import torch\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from NewSample import coords_to_dists, loss_fcn, coord_to_dcd, smooth_transition_loss_by_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b76a518-af2f-4095-9e2d-1fb482bf8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(object):\n",
    "    return object if type(object) == list else [object]\n",
    "\n",
    "def parse_filename(filename):\n",
    "    filename = filename.split('/')[-1]  # remove directory path\n",
    "    components = filename.split('_')\n",
    "    region_idx = int(components[1])\n",
    "    cond_scale = float(components[2]) if '.' in components[2] else int(components[2])\n",
    "    rescaled_phi = float(components[3]) if '.' in components[3] else int(components[3])\n",
    "    milestone = int(components[4])\n",
    "    chrom = components[5].split('.')[0]\n",
    "\n",
    "    return region_idx, cond_scale, rescaled_phi, milestone, chrom\n",
    "\n",
    "def is_valid(\n",
    "    filename,\n",
    "    region_idx,\n",
    "    cond_scale,\n",
    "    rescaled_phi,\n",
    "    milestone,\n",
    "    chrom\n",
    "):\n",
    "\n",
    "    try:\n",
    "        ri, cs, rp, ms, ch = parse_filename(filename) \n",
    "    except:\n",
    "        return False, (None, None, None, None, None)\n",
    "    \n",
    "    for desired,actual in [(region_idx,ri),(cond_scale,cs),\n",
    "                         (rescaled_phi,rp),(milestone,ms),(chrom,ch)]:\n",
    "        if desired is not None and actual not in to_list(desired):\n",
    "            return False, (ri, cs, rp, ms, ch)\n",
    "    \n",
    "    return True, (ri, cs, rp, ms, ch)\n",
    "    \n",
    "def get_all_sample_types(\n",
    "    sample_directory,\n",
    "    *,\n",
    "    region_idx=None,\n",
    "    cond_scale=None,\n",
    "    rescaled_phi=None,\n",
    "    milestone=None,\n",
    "    chrom = None\n",
    "):\n",
    "    samples = os.listdir(sample_directory)\n",
    "\n",
    "    to_process = pd.DataFrame({\n",
    "        'region_idx':[],\n",
    "        'cond_scale':[],\n",
    "        'rescaled_phi':[],\n",
    "        'milestone':[],\n",
    "        'chrom':[],\n",
    "    })\n",
    "    \n",
    "    for f in samples:\n",
    "        valid, properties = is_valid(f,region_idx,cond_scale,rescaled_phi,milestone,chrom) \n",
    "        if valid: \n",
    "            to_process.loc[len(to_process)] = properties\n",
    "\n",
    "    to_process.sort_values(\n",
    "        ['milestone','chrom','region_idx','cond_scale','rescaled_phi'], # sorts in this order\n",
    "        inplace=True,\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    return [*to_process.itertuples(index=False,name=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03de9135-6b4a-43ef-823a-99112b33a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_best_alignments(t_ref,t_sample):\n",
    "    '#''\n",
    "    Efficiency could be improved by simply finding the best distance alignments, which\n",
    "    are independent of coordinate superimposition, then only aligning the relevant structures,\n",
    "    rather than aligning all before comparing distance maps\n",
    "    '#''\n",
    "    ref_dists = coords_to_dists(torch.from_numpy(t_ref.xyz))\n",
    "    while ref_dists.ndim < 3: # Shouldn't happen unless only one structure was available\n",
    "        ref_dists = ref_dists.unsqueeze(0)\n",
    "    #ref_dists = ref_dists.unsqueeze(1).expand(-1,len(t_sample),-1,-1)\n",
    "        \n",
    "    best_alignments = []\n",
    "    for frame in range(len(t_ref)):\n",
    "\n",
    "        # This is an in-place operation\n",
    "        t_sample.superpose(t_ref,frame=frame)\n",
    "\n",
    "        # Measure similarities\n",
    "        ref_dist = ref_dists[frame,...]\n",
    "        sample_coords = torch.from_numpy(t_sample.xyz)\n",
    "        losses = torch.tensor([\n",
    "            loss_fcn(sample_coords[i,:,:],ref_dist) for i in range(len(t_sample))\n",
    "        ]) # Should already be flat\n",
    "        losses/= ref_dist.numel()\n",
    "        min_loss,min_loss_idx = losses.max(0)\n",
    "\n",
    "        best_alignments.append(\n",
    "            (min_loss,int(min_loss_idx),sample_coords[min_loss_idx,...])\n",
    "        )\n",
    "\n",
    "    best_info = [{'Loss':loss,'Index':idx} for loss,idx,_ in best_alignments]\n",
    "    best_alignments = torch.stack([coords for _,_,coords in best_alignments],dim=0)\n",
    "\n",
    "    return best_info,best_alignments\n",
    "'''\n",
    "def get_best_alignments(t_ref,t_sample,r_c=1.,long_scale=1/8,use_gpu=True,high_precision=False):\n",
    "\n",
    "    ref_dists = coords_to_dists(torch.from_numpy(t_ref.xyz))\n",
    "    ref_dists = ref_dists.unsqueeze(1).expand(-1,len(t_sample),-1,-1)\n",
    "    sample_dists = coords_to_dists(torch.from_numpy(t_sample.xyz))\n",
    "    sample_dists = sample_dists.unsqueeze(0).expand(len(t_ref),-1,-1,-1)\n",
    "\n",
    "    losses = smooth_transition_loss_by_sample(sample_dists,ref_dists,r_c,long_scale,use_gpu,high_precision)\n",
    "\n",
    "    best_loss,best_loss_idx = losses.min(1)\n",
    "    \n",
    "    coords = torch.empty(*t_ref.xyz.shape)\n",
    "    for frame,idx in enumerate(best_loss_idx):\n",
    "        ts1 = t_sample[idx]\n",
    "        ts2 = copy.deepcopy(ts1)\n",
    "        ts2.xyz[...,-1]*= -1 # Reflect, in case we computed the isomer with backward chirality\n",
    "        ts1.superpose(t_ref,frame=frame)\n",
    "        ts2.superpose(t_ref,frame=frame)\n",
    "\n",
    "        diff1 = ((t_ref[frame].xyz - ts1.xyz)**2).sum()\n",
    "        diff2 = ((t_ref[frame].xyz - ts2.xyz)**2).sum()\n",
    "        if diff1 < diff2: \n",
    "            coords[frame,...] = torch.from_numpy(ts1.xyz).squeeze(0)\n",
    "        else:\n",
    "            coords[frame,...] = torch.from_numpy(ts2.xyz).squeeze(0)\n",
    "\n",
    "    best_info = [\n",
    "        {\n",
    "            'Loss':best_loss[i],\n",
    "            'Index':best_loss_idx[i]\n",
    "        } for i in range(len(best_loss))\n",
    "    ]\n",
    "    \n",
    "    return best_info,coords\n",
    "    \n",
    "\n",
    "def get_gen_filepaths(\n",
    "    sample_dir,\n",
    "    region_idx,\n",
    "    cond_scale,\n",
    "    rescaled_phi,\n",
    "    milestone,\n",
    "    chrom\n",
    "):\n",
    "    \n",
    "    filepath = sample_dir\n",
    "    if filepath != '' and filepath[-1] != '/':\n",
    "        filepath+= '/'\n",
    "    filepath+= f'sample_{region_idx}_{float(cond_scale)}_{float(rescaled_phi)}'\n",
    "    filepath+= f'_{milestone}_{chrom}'\n",
    "    return filepath+'.dcd', filepath+'.psf'\n",
    "\n",
    "def get_tan_filepaths(\n",
    "    sample_dir,\n",
    "    chrom,\n",
    "    region_idx,\n",
    "    nbins\n",
    "):\n",
    "    filepath = sample_dir\n",
    "    if filepath != '' and filepath[-1] != '/':\n",
    "        filepath+= '/'\n",
    "    filepath+= f'chrom_{chrom}_region_{region_idx}_nbins_{nbins}'\n",
    "    return filepath+'.dcd',filepath+'.psf'\n",
    "\n",
    "def align_many_samples(\n",
    "    sample_dir,\n",
    "    reference_dir,\n",
    "    *,\n",
    "    chroms=None,\n",
    "    milestones=None,\n",
    "    region_idxs=None,\n",
    "    cond_scales=None,\n",
    "    rescaled_phis=None,\n",
    "    r_c=1.,\n",
    "    long_scale=1/8,\n",
    "    use_gpu=True,\n",
    "    high_precision=False,\n",
    "):\n",
    "    sample_types = get_all_sample_types(\n",
    "        sample_directory=sample_dir,\n",
    "        region_idx=region_idxs,\n",
    "        cond_scale=cond_scales,\n",
    "        rescaled_phi=rescaled_phis,\n",
    "        milestone=milestones,\n",
    "        chrom = chroms\n",
    "    )\n",
    "\n",
    "    if sample_dir != '' and sample_dir[-1] != '/':\n",
    "        sample_dir = sample_dir + '/'\n",
    "    dest_dir = sample_dir + 'aligned/'\n",
    "\n",
    "    #with tqdm(initial = 0, total = len(sample_types), disable = False) as pbar:\n",
    "    for region_idx, cond_scale, rescaled_phi, milestone, chrom in tqdm(sample_types,desc='Sample Alignment Progress'):\n",
    "        # Load generated samples\n",
    "        gen_dcd,gen_psf = get_gen_filepaths(sample_dir,region_idx,cond_scale,rescaled_phi,milestone,chrom)\n",
    "        t_gen = md.load(gen_dcd,top=gen_psf)\n",
    "\n",
    "        # Load reference samples\n",
    "        nbins = t_gen.xyz.shape[-2]\n",
    "        ref_dcd,ref_psf = get_tan_filepaths(reference_dir,chrom,region_idx,nbins)\n",
    "        t_ref = md.load(ref_dcd,top=ref_psf)\n",
    "\n",
    "        # Align the data, place configurations into a \n",
    "        info,coords = get_best_alignments(t_ref,t_gen,r_c,long_scale,use_gpu,high_precision)\n",
    "\n",
    "        # Save the information\n",
    "        sample_name = '.'.join(gen_dcd.split('/')[-1].split('.')[:-1])\n",
    "        coord_to_dcd(coords,dest_dir,sample_name)\n",
    "        pickle.dump(info,open(dest_dir+sample_name+'_loss_info.pkl','wb'))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd038463-de3f-4edb-a0fc-f0021df0af72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe52f682f1b848db9f1cf30e12f97a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample Alignment Progress:   0%|          | 0/2670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malign_many_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/samples/origami_64_no_embed_reduction/dcd_files/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/samples/Tan/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchroms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#'1',\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmilestones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregion_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#330,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond_scales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#3.0,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrescaled_phis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[38;5;66;43;03m#.5\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 144\u001b[0m, in \u001b[0;36malign_many_samples\u001b[0;34m(sample_dir, reference_dir, chroms, milestones, region_idxs, cond_scales, rescaled_phis, r_c, long_scale, use_gpu, high_precision)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Save the information\u001b[39;00m\n\u001b[1;32m    143\u001b[0m sample_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(gen_dcd\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 144\u001b[0m \u001b[43mcoord_to_dcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(info,\u001b[38;5;28mopen\u001b[39m(dest_dir\u001b[38;5;241m+\u001b[39msample_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_loss_info.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/refining_scHiC/revamp_with_zhuohan/code/data_utils/NewSample.py:377\u001b[0m, in \u001b[0;36mcoord_to_dcd\u001b[0;34m(coords, dest_dir, sample_name)\u001b[0m\n\u001b[1;32m    375\u001b[0m xyz_files \u001b[38;5;241m=\u001b[39m [temp_xyz_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmol_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xyz\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mol \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_molecules)]\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mol,fp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(xyz_files):\n\u001b[0;32m--> 377\u001b[0m     \u001b[43mcoord_to_xyz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m t \u001b[38;5;241m=\u001b[39m md\u001b[38;5;241m.\u001b[39mload(xyz_files,top\u001b[38;5;241m=\u001b[39mpsf_filepath)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# Remove the now-unneeded xyz files\u001b[39;00m\n",
      "File \u001b[0;32m~/refining_scHiC/revamp_with_zhuohan/code/data_utils/NewSample.py:343\u001b[0m, in \u001b[0;36mcoord_to_xyz\u001b[0;34m(coords, filepath)\u001b[0m\n\u001b[1;32m    331\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_atoms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    334\u001b[0m ]\n\u001b[1;32m    335\u001b[0m lines\u001b[38;5;241m.\u001b[39mextend([\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m     ]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_atoms)\n\u001b[1;32m    342\u001b[0m ])\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    344\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lines))\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/python-LLM-2023b/lib/python3.10/codecs.py:186\u001b[0m, in \u001b[0;36mIncrementalEncoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    An IncrementalEncoder encodes an input in multiple steps. The input can\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    be passed piece by piece to the encode() method. The IncrementalEncoder\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    remembers the state of the encoding process between calls to encode().\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        Creates an IncrementalEncoder instance.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m        for a list of possible values.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m errors\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "align_many_samples(\n",
    "    '../../data/samples/origami_64_no_embed_reduction/dcd_files/',\n",
    "    '../../data/samples/Tan/',\n",
    "    chroms=None,#'1',\n",
    "    milestones=120,\n",
    "    region_idxs=None,#330,\n",
    "    cond_scales=None,#3.0,\n",
    "    rescaled_phis=None#.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be8f54e-b3d9-4737-97b5-f1d22cd21674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df634b09000c4a02b2668d3e3056d695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample Alignment Progress:   0%|          | 0/2670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pairwise_alignment import align_many_samples\n",
    "align_many_samples(\n",
    "    '../../data/samples/origami_64_no_embed_reduction/dcd_files/',\n",
    "    '../../data/samples/Tan/',\n",
    "    chroms=None,#'1',\n",
    "    milestones=120,\n",
    "    region_idxs=None,#330,\n",
    "    cond_scales=None,#3.0,\n",
    "    rescaled_phis=None#.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854a14b-1600-4f12-a425-c4cd7d33e1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa7841-ee51-4a9e-a726-aa2752e42c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e8859a-9f4f-41c5-a8b6-a420b69cf7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.19516110420227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "tt = -time.time()\n",
    "align_many_samples(\n",
    "    '../../data/samples/origami_64_no_embed_reduction/dcd_files/',\n",
    "    '../../data/samples/Tan/',\n",
    "    chroms='1',\n",
    "    milestones=120,\n",
    "    region_idxs=330,\n",
    "    cond_scales=3.0,\n",
    "    rescaled_phis=.5\n",
    ")\n",
    "tt+= time.time()\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26163a-16d7-42a6-b536-077f7d200372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17caa15f-849b-4a60-881c-50fb0db94d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38220415-3530-4177-a4c2-d0403415a79e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malign_many_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/samples/origami_64_no_embed_reduction/dcd_files/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/samples/Tan/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchroms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#'1',\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmilestones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregion_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#330,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond_scales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#3.0,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrescaled_phis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[38;5;66;43;03m#.5\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 139\u001b[0m, in \u001b[0;36malign_many_samples\u001b[0;34m(sample_dir, reference_dir, chroms, milestones, region_idxs, cond_scales, rescaled_phis)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Save the information\u001b[39;00m\n\u001b[1;32m    138\u001b[0m sample_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(gen_dcd\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 139\u001b[0m \u001b[43mcoord_to_dcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(info,\u001b[38;5;28mopen\u001b[39m(dest_dir\u001b[38;5;241m+\u001b[39msample_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_loss_info.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/refining_scHiC/revamp_with_zhuohan/code/data_utils/NewSample.py:336\u001b[0m, in \u001b[0;36mcoord_to_dcd\u001b[0;34m(coords, dest_dir, sample_name)\u001b[0m\n\u001b[1;32m    334\u001b[0m xyz_files \u001b[38;5;241m=\u001b[39m [temp_xyz_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmol_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xyz\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mol \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_molecules)]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mol,fp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(xyz_files):\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mcoord_to_xyz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m t \u001b[38;5;241m=\u001b[39m md\u001b[38;5;241m.\u001b[39mload(xyz_files,top\u001b[38;5;241m=\u001b[39mpsf_filepath)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Remove the now-unneeded xyz files\u001b[39;00m\n",
      "File \u001b[0;32m~/refining_scHiC/revamp_with_zhuohan/code/data_utils/NewSample.py:302\u001b[0m, in \u001b[0;36mcoord_to_xyz\u001b[0;34m(coords, filepath)\u001b[0m\n\u001b[1;32m    290\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_atoms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    293\u001b[0m ]\n\u001b[1;32m    294\u001b[0m lines\u001b[38;5;241m.\u001b[39mextend([\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m     ]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_atoms)\n\u001b[1;32m    301\u001b[0m ])\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    303\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lines))\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/python-LLM-2023b/lib/python3.10/codecs.py:186\u001b[0m, in \u001b[0;36mIncrementalEncoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    An IncrementalEncoder encodes an input in multiple steps. The input can\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    be passed piece by piece to the encode() method. The IncrementalEncoder\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    remembers the state of the encoding process between calls to encode().\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        Creates an IncrementalEncoder instance.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m        for a list of possible values.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m errors\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "align_many_samples(\n",
    "    '../../data/samples/origami_64_no_embed_reduction/dcd_files/',\n",
    "    '../../data/samples/Tan/',\n",
    "    chroms=None,#'1',\n",
    "    milestones=120,\n",
    "    region_idxs=None,#330,\n",
    "    cond_scales=None,#3.0,\n",
    "    rescaled_phis=None#.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117650b3-13dd-46be-a3a4-4856333e3ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138c44f-69ca-48d9-bbf3-9e514d5cfee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffadf5-f234-4271-8474-b6c66f8e60ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0cb1716-4700-4cfb-9ffa-5cd958e62252",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = md.load(\n",
    "    '../../data/samples/origami_64_no_embed_reduction/dcd_files/sample_200_0.5_0.0_36_1.dcd',\n",
    "    top = '../../data/samples/origami_64_no_embed_reduction/dcd_files/sample_200_0.5_0.0_36_1.psf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3a7574-22e1-4f2a-a0fa-21d9474b4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = md.load(\n",
    "    '../../data/samples/Tan/chrom_1_region_200_nbins_64.dcd',\n",
    "    top = '../../data/samples/Tan/chrom_1_region_200_nbins_64.psf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327ba0a1-0b3e-4646-95ad-8684fcdd3f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(t))\n",
    "print(len(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3101f9-765d-4a70-8747-da884c203ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daec853b-1233-44ec-998f-685e945d74ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76216b7e-4a73-4e97-ad7b-455ed44df08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1919"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c282d2b-fb7a-4cf1-bd95-ba7825f82ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1919 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05ad0a-5f48-4ef9-8c5b-637d119ecca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f32165-f23d-4be4-a236-83eb8ea084e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebe39a30-5839-4d1e-bc05-2c9a397e98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = copy.deepcopy(t)\n",
    "t2.xyz[...,2]*= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b1c3fec-5a13-44b4-b437-fd7ab5adb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,5,5).sum((-1,-2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce1ffe8-3d16-4f0b-9d73-7629ae8f6e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdtraj.Trajectory with 90 frames, 64 atoms, 1 residues, without unitcells at 0x7f8f6e658310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "108dbc3a-81b5-4d16-b8a7-4bee8266c01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[0].xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6243d2b9-1214-404c-b359-8b3446e155d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1919, 90])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cf1ae89-fd9d-433f-b20c-f68ac8c3a77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = losses.min(0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33720280-b404-4b82-9781-bc1dd272a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.114803162908151"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(np.random.rand(5)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b0195a8-7627-4ad7-9c34-c9a38e2f316a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4931640625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000 * 90 * 8 * 64**2 / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd0fffe-8e56-4a73-9d88-9f59bdba7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand(5,5,5)\n",
    "mask=torch.where(a<.5)#,dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "465f8550-3110-42b0-9ee9-0a71dc63ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_transition_one_element(output,target,r_c,long_scale,m,b):\n",
    "    diff = max(output-target,target-output) / r_c\n",
    "    if diff < 1:\n",
    "        return diff**2\n",
    "    else:\n",
    "        return m*diff**long_scale + b\n",
    "\n",
    "def smooth_transition_loss_by_sample(\n",
    "    output,\n",
    "    target,\n",
    "    r_c=1.0, # Transition distance from x**2 -> x**(long_scale)\n",
    "    long_scale=1/8,\n",
    "    use_gpu=True,\n",
    "    high_precision=True\n",
    "):\n",
    "    '''\n",
    "    Reduces to smooth L1 loss if  long_scale == 1.\n",
    "    \n",
    "    Rather than summing over ALL data, sum over the final two \n",
    "    dimensions (corresponding to individual distance maps). \n",
    "    '''\n",
    "    # Scale to ensure the two functions have the same slope at r_c\n",
    "    m = 2 / long_scale\n",
    "    # Shift to ensure the two functions have the same value at r_c\n",
    "    b = 1 - m\n",
    "    \n",
    "    return_device = output.device\n",
    "    return_dtype = output.dtype\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        output = output.cuda()\n",
    "        target = target.cuda()\n",
    "    if high_precision:\n",
    "        output = output.double()\n",
    "        target = target.double()\n",
    "\n",
    "    losses = (output - target).abs_()\n",
    "    del output, target\n",
    "    losses/= r_c\n",
    "    \n",
    "    if losses.is_cuda:\n",
    "        '''\n",
    "        This is slower than using masking, but it avoid memory issues associated\n",
    "        with mask indexing (torch turns bool masks into int64 indexing arrays) while\n",
    "        remaining faster than some alternative low-memory options I tried. \n",
    "        '''\n",
    "    \n",
    "        #losses = torch.where(\n",
    "        #    losses < 1,\n",
    "        #    losses.square(),\n",
    "        #    m*losses.pow(long_scale)+b,\n",
    "        #    out=losses\n",
    "        #)\n",
    "        torch.where(\n",
    "            losses < 1,\n",
    "            losses.square(),\n",
    "            m*losses.pow(long_scale)+b,\n",
    "            out=losses\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        '''\n",
    "        Assume that these memory issues don't arise on the CPU\n",
    "        '''\n",
    "        mask = losses < 1\n",
    "        if mask.any():\n",
    "            #losses[mask].square_()\n",
    "            losses[mask] = losses[mask]**2\n",
    "        mask^= True\n",
    "        if mask.any():\n",
    "            losses[mask] = m*losses[mask]**long_scale + b\n",
    "        del mask\n",
    "    \n",
    "\n",
    "    return losses.sum((-1,-2)).to(dtype=return_dtype,device=return_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c033268e-b70e-4fe0-8b12-81e938e5d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = coords_to_dists(torch.from_numpy(t1.xyz))\n",
    "dist2 = coords_to_dists(torch.from_numpy(t.xyz))\n",
    "dist1 = dist1.unsqueeze(1).expand(-1,dist2.shape[0],-1,-1)\n",
    "dist2 = dist2.unsqueeze(0).expand(dist1.shape[0],-1,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9ba5e69-c790-4f77-bba9-a1f4fbbb1262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5471458435058594"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = -time.time()\n",
    "losses = smooth_transition_loss_by_sample(dist1,dist2,use_gpu=True)\n",
    "tt+= time.time()\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dbf7a019-b907-4993-a3b8-28ab5f7c0d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2595009803771973"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = -time.time()\n",
    "losses1 = smooth_transition_loss_by_sample(dist1,dist2,use_gpu=False)\n",
    "tt+= time.time()\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ac91d-c536-424d-8c5c-d6ae15c753af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628bf72-b722-4f2f-85ce-c6424dafc1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56788d9e-f611-4384-a823-5e2484cd5c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae8bf99-1c21-46b8-a440-2d3ade5733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(5,10,3)\n",
    "b = torch.linalg.norm(a,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469e91c7-1d76-423a-aa59-9e85efbf1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6148e2b-3b9c-49a0-8a4b-c8681bb7f8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.vecdot(a[...,:1],a,dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affd4317-a65b-43bd-ad55-8aef242acedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4869, 1.0372, 1.2529, 0.8914, 0.3977, 1.1891, 1.3347, 0.4880, 0.6940,\n",
       "         1.0607],\n",
       "        [   inf,    inf,    inf,    inf,    inf,    inf,    inf,    inf,    inf,\n",
       "            inf],\n",
       "        [1.3215, 0.9294, 0.9438, 0.8269, 0.9954, 0.9360, 0.6900, 1.2909, 1.2902,\n",
       "         1.1081],\n",
       "        [1.1064, 0.8872, 1.1795, 0.8327, 0.7717, 1.0095, 1.0139, 1.1269, 0.4704,\n",
       "         1.1709],\n",
       "        [0.8528, 0.4068, 0.9754, 0.7854, 0.8601, 1.2958, 1.3150, 0.7143, 1.0410,\n",
       "         0.8614]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1,:] = torch.nan\n",
    "b.nan_to_num_(torch.inf)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73b900a8-f14a-4a31-b9a3-5a05620a72a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor(0.),\n",
       "indices=tensor(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(5)\n",
    "a.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cafcf-e1dd-4f5a-8e4c-c01705bb42f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
