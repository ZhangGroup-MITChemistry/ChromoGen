{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c44e97-9f07-4c6b-bbdd-b800016b956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 12:31:33.558720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data\n",
      "Loading Configuration Dataset\n",
      "Loading Embeddings\n",
      "Constructing DataLoader\n",
      "Data Preparation Complete\n"
     ]
    }
   ],
   "source": [
    "# Training data locations\n",
    "config_fp = '../../data/processed_data.hdf5'\n",
    "embedding_dir = '../../data/embeddings/'\n",
    "\n",
    "# Supporting data locations \n",
    "mean_dist_fp = '../../data/mean_dists.pt'\n",
    "mean_sq_dist_fp='../../data/squares.pt'\n",
    "\n",
    "# Exclude chromosome X from training data so that it can be\n",
    "# used for network validation \n",
    "training_chroms = ['X']# [f'{k}' for k in range(1,23)]\n",
    "\n",
    "# Training iteration details \n",
    "segment_length = 65\n",
    "batch_size = 64\n",
    "shuffle_data = True\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# Import modules\n",
    "###########################################################\n",
    "\n",
    "# This should eventually be performed via relative imports\n",
    "import sys\n",
    "sys.path.insert(0,'/home/gridsan/gschuette/refining_scHiC/revamp_with_zhuohan/code/diffusion/')\n",
    "from classifier_free_guidance_greg import GaussianDiffusion, Unet, Trainer\n",
    "sys.path.insert(1,'/home/gridsan/gschuette/refining_scHiC/revamp_with_zhuohan/code/data_utils_v2/')\n",
    "from DataLoader import DataLoader\n",
    "from ConfigDataset import ConfigDataset\n",
    "from EmbeddedRegions import EmbeddedRegions\n",
    "\n",
    "import pickle # Temporary \n",
    "###########################################################\n",
    "# Build the DataLoader with corresponding datasets. \n",
    "###########################################################\n",
    "\n",
    "print('Preparing Data',flush=True)\n",
    "print('Loading Configuration Dataset',flush=True)\n",
    "config_ds = ConfigDataset(\n",
    "    config_fp,\n",
    "    segment_length=segment_length,\n",
    "    batch_size=0,\n",
    "    normalize_distances=True,\n",
    "    geos=None,\n",
    "    organisms=None,\n",
    "    cell_types=None,\n",
    "    cell_numbers=None,\n",
    "    chroms=training_chroms,\n",
    "    replicates=None,\n",
    "    shuffle=True,\n",
    "    allow_overlap=True,\n",
    "    two_channels=False,\n",
    "    try_GPU=True,\n",
    "    mean_dist_fp=mean_dist_fp,\n",
    "    mean_sq_dist_fp=mean_sq_dist_fp\n",
    ")\n",
    "\n",
    "print('Loading Embeddings',flush=True)\n",
    "er = EmbeddedRegions(\n",
    "    embedding_dir,\n",
    "    chroms=training_chroms\n",
    ")\n",
    "\n",
    "print('Constructing DataLoader',flush=True)\n",
    "import copy\n",
    "dl = DataLoader(\n",
    "    config_ds,\n",
    "    copy.deepcopy(er),\n",
    "    drop_unmatched_pairs=True, \n",
    "    shuffle = shuffle_data,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "print('Data Preparation Complete',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433165db-ae22-4615-abc4-938c020e7ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6123,  0.7266,  0.9655,  ...,  1.2505,  1.0122, -1.6800],\n",
       "         [ 0.0224,  2.0133,  0.8625,  ...,  1.9802,  1.3560, -0.0659],\n",
       "         [ 1.2121,  1.6755,  0.8499,  ...,  0.6848,  0.2985,  0.3713],\n",
       "         ...,\n",
       "         [-0.1885, -1.1116, -0.1385,  ..., -0.9337, -0.5839,  0.9992],\n",
       "         [ 1.2031, -0.5500,  0.7680,  ...,  0.0438,  1.3433,  0.6109],\n",
       "         [ 0.2135, -0.3050,  0.3904,  ...,  0.4092,  0.5942,  0.9343]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er.data.loc[(1300000, 'X', 23600000),'Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfec2c9-992f-41be-9d21-34314e280687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23520000, 23520000, 23520000, 23520000, 23520000, 23520000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23540000, 23540000, 23540000, 23540000, 23540000, 23540000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23560000, 23560000, 23560000, 23560000, 23560000, 23560000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23580000, 23580000, 23580000, 23580000, 23580000, 23580000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23600000, 23600000, 23600000, 23600000, 23600000, 23600000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23620000, 23620000, 23620000, 23620000, 23620000, 23620000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000,\n",
       "       23640000, 23640000, 23640000, 23640000, 23640000, 23640000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = [i[2] for i in dl.embed_idx]\n",
    "a.sort()\n",
    "a = np.array(a)\n",
    "a[(a<23650000)&(a>23500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabca8db-838a-437b-9a85-ec3e43efe42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "c,image_size,_ = tuple(config_ds.fetch((0,'mat'))[0].shape)\n",
    "model = Unet(\n",
    "    dim=64,\n",
    "    #num_classes,\n",
    "    cond_drop_prob = 0.5,\n",
    "    init_dim = None,\n",
    "    out_dim = None,\n",
    "    dim_mults=(1, 2, 4, 8),\n",
    "    channels = c,\n",
    "    resnet_block_groups = 8,\n",
    "    learned_variance = False,\n",
    "    learned_sinusoidal_cond = False,\n",
    "    random_fourier_features = False,\n",
    "    learned_sinusoidal_dim = 16,\n",
    "    attn_dim_head = 32,\n",
    "    attn_heads = 4,\n",
    "    embedding_dimensions=tuple(er.ifetch(0)[0].shape)\n",
    ")\n",
    "\n",
    "print(image_size,flush=True)\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=image_size,\n",
    "    timesteps = 1000,\n",
    "    sampling_timesteps = None,\n",
    "    objective = 'pred_noise',\n",
    "    beta_schedule = 'cosine',\n",
    "    ddim_sampling_eta = 1.,\n",
    "    offset_noise_strength = 0.,\n",
    "    min_snr_loss_weight = False,\n",
    "    min_snr_gamma = 5\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    dl,\n",
    "    train_batch_size = 128,\n",
    "    gradient_accumulate_every = 1,\n",
    "    augment_horizontal_flip = True,\n",
    "    train_lr = 1e-4,\n",
    "    train_num_steps = 600000,\n",
    "    ema_update_every = 10,\n",
    "    ema_decay = 0.995,\n",
    "    adam_betas = (0.9, 0.99),\n",
    "    save_and_sample_every = 5000,\n",
    "    num_samples = 25,\n",
    "    results_folder = './results_small',\n",
    "    amp = False, # using false here turns off mixed precision \n",
    "    mixed_precision_type = 'fp16',\n",
    "    split_batches = True,\n",
    "    convert_image_to = None,\n",
    "    calculate_fid = False, #True,\n",
    "    inception_block_idx = 2048,\n",
    "    max_grad_norm = 1.,\n",
    "    num_fid_samples = 50000,\n",
    "    save_best_and_latest_only = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daee9899-2483-417e-98b3-bb168e7c8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class DataProcessor: \n",
    "    def __init__(\n",
    "        self,\n",
    "        mean_dist_fp='../../data/mean_dists.pt',\n",
    "        mean_sq_dist_fp='../../data/squares.pt',\n",
    "        dtype=torch.double,\n",
    "        seg_len = None, # Number of beads\n",
    "        device = None,\n",
    "        preserve_asymmetries=True,\n",
    "        data = None,\n",
    "        data_is_flat = None,\n",
    "        preserve_data_dtype = True\n",
    "    ): \n",
    "\n",
    "        # Assume GPU is desired unless specified otherwise\n",
    "        if device is None: \n",
    "            try:\n",
    "                device = torch.empty(1).cuda().device\n",
    "            except:\n",
    "                device = torch.empty(1).device\n",
    "\n",
    "        mean_dist = torch.load(mean_dist_fp,map_location=device).flatten().to(dtype)\n",
    "        mean_square_dist = torch.load(mean_sq_dist_fp,map_location=device).flatten().to(dtype)\n",
    "        if seg_len is not None: \n",
    "            mean_dist = mean_dist[:seg_len]\n",
    "            mean_square_dist = mean_square_dist[:seg_len]\n",
    "        \n",
    "        self.dist_std = (mean_square_dist - mean_dist**2).sqrt()\n",
    "        self.inv_beta = torch.sqrt( 2*mean_square_dist/3 )\n",
    "        self.inv_beta_sigmoid = torch.sigmoid( -self.inv_beta/self.dist_std )\n",
    "        self.complement_inv_beta_sigmoid = 1 - self.inv_beta_sigmoid\n",
    "\n",
    "        self.preserve_asymmetries = preserve_asymmetries\n",
    "        if data is not None: \n",
    "            self.set_data(data,data_is_flat,preserve_data_dtype)\n",
    "        else: \n",
    "            self.data = data\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.dist_std.dtype\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.dist_std.device\n",
    "\n",
    "    @property\n",
    "    def seg_len(self): \n",
    "        return len(self.dist_std)\n",
    "\n",
    "    def __len__(self): \n",
    "        if self.batch is None: \n",
    "            return 0\n",
    "        elif len(self.data.shape) == 1:\n",
    "            return 1\n",
    "        elif (len(self.data.shape) == 2) and (not self.is_flat):\n",
    "            return 1\n",
    "        else:\n",
    "            return self.data.shape[0]\n",
    "        \n",
    "    def to(self,*args):\n",
    "        for attr in dir(self): \n",
    "            if type(getattr(self, attr)) == torch.Tensor:\n",
    "                for arg in args:\n",
    "                    setattr(self, attr, getattr(self, attr).clone().to(arg))\n",
    "\n",
    "    #####\n",
    "    # Processing data\n",
    "    def _infer_seg_len_(self): \n",
    "        # sample_len is an integer with length N(N-1)//2 \n",
    "        if self.is_flat is None: \n",
    "            # Must infer matrix vs flattened form \n",
    "            if (len(self.batch.shape) == 1) or (self.batch.shape[-1] != self.batch.shape[-2]):\n",
    "                self.is_flat = True\n",
    "            else: \n",
    "                # Assumes batch.shape[-1] == batch.shape[-2] only occurs if in matrix form, \n",
    "                # which is overwhelmingly likely. \n",
    "                self.is_flat = False \n",
    "        \n",
    "        if self.is_flat:\n",
    "            M = self.batch.shape[0] \n",
    "            NN = (1+np.sqrt(1+8*M))/2 # Quadratic formula\n",
    "            N = int(NN)\n",
    "            assert N == NN, f'Invalid batch size. Cannot infer number of beads in the segment!'\n",
    "        else: \n",
    "            assert len(self.batch.shape) > 1, \\\n",
    "            'User indicated that the provided batch was not flattened, but one-dimensional data was provided!'\n",
    "            N = self.batch.shape[-1]\n",
    "\n",
    "        # Finally, compute the number of beads in the segment. \n",
    "        self.batch_seg_len = N \n",
    "        self.triu_indices = torch.triu_indices(N,N,0)\n",
    "        self.sep = self.triu_indices[1] - self.triu_indices[0] \n",
    "\n",
    "    def flatten(self): \n",
    "        \n",
    "        if self.is_flat:\n",
    "            return self.batch.clone()\n",
    "\n",
    "        i,j = self.triu_indices\n",
    "        return self.batch[...,i,j].clone()\n",
    "        \n",
    "    \n",
    "    def flatten_(self,force=False):\n",
    "\n",
    "        if self.is_flat:\n",
    "            return \n",
    "\n",
    "        b = self.batch\n",
    "        if not force and self.preserve_asymmetries and (b != b.transpose(-2,-1)).any():\n",
    "            return # Flattening would cause us to lose the asymmetry in the matrix\n",
    "\n",
    "        i,j = self.triu_indices\n",
    "\n",
    "        self.batch = b[...,i,j]\n",
    "        self.is_flat = True\n",
    "\n",
    "    def unflatten(self):\n",
    "\n",
    "        if not self.is_flat:\n",
    "            return self.batch.clone() # Already in matrix form\n",
    "\n",
    "        batch = torch.empty(*self.batch.shape[:-1],self.batch_seg_len,self.batch_seg_len,dtype=self.dtype,device=self.device)\n",
    "        i,j = self.triu_indices\n",
    "\n",
    "        batch[...,i,j] = self.batch \n",
    "        batch[...,j,i] = self.batch \n",
    "        \n",
    "        return batch \n",
    "    \n",
    "    def unflatten_(self):\n",
    "\n",
    "        self.batch = self.unflatten()\n",
    "        self.is_flat = False \n",
    "    \n",
    "    \n",
    "    def set_data(self,batch,is_flat=None,return_original_dtype=True):\n",
    "        # is_flat == True: Last dimension contains the upper triangle of the distance matrix. \n",
    "        # is_flat == False: Data is still in matrix form, in the final 2 dimensions. \n",
    "        # is_flat is None: Must infer whether data is in the matrix or flattened form.\n",
    "\n",
    "        # Convert numpy objects to torch tensors\n",
    "        if type(batch) == np.ndarray: \n",
    "            batch = torch.from_numpy(batch) \n",
    "\n",
    "        # Validate input. \n",
    "        assert type(batch) == torch.Tensor, \\\n",
    "        f'The batch argument must be a torch.Tensor. Received {type(batch)}'\n",
    "        \n",
    "        assert type(is_flat)==bool or is_flat is None, \\\n",
    "        f'The is_flat argument must be one of True, False, or None. Received {type(is_flat)}'\n",
    "        \n",
    "        assert type(return_original_dtype) == bool, \\\n",
    "        f'The return_original_dtype argument must be either True or False. Received {type(return_original_dtype)}.'\n",
    "\n",
    "        # Save the data to this DataProcessor object\n",
    "        self.batch_dtype = batch.dtype if return_original_dtype else self.dtype\n",
    "        self.batch = batch.clone().to(self.device,self.dtype)\n",
    "        self.is_flat = is_flat\n",
    "        self._infer_seg_len_() # Determines the number of genomic loci in the map\n",
    "        self.flatten_() # Reduces memory usage & computational requirements. \n",
    "\n",
    "        # Infer whether this is in the normalized or distance form \n",
    "        self.normalized = (self.batch <= 1).all()\n",
    "\n",
    "    ''' # Must still add this functionality \n",
    "    def normalize_dists(self,dists):\n",
    "        if not self.norm_dists:\n",
    "            return dists\n",
    "        sep = self.sep_idx\n",
    "        i,j = self.triu_indices\n",
    "        bs = dists.shape[0] #self.batch_size\n",
    "        j = j-1\n",
    "        dists-= self.inv_beta[sep].repeat(bs,1) # Should eventually replace with expand to save memory \n",
    "        dists/= self.dist_std[sep].repeat(bs,1)\n",
    "        dists.sigmoid_()\n",
    "        dists-= self.inv_beta_sigmoid[sep].repeat(bs,1)\n",
    "        dists/= self.complement_inv_beta_sigmoid[sep].repeat(bs,1)\n",
    "        return dists \n",
    "    '''\n",
    "\n",
    "    def _unnormalize_(self): \n",
    "        # Dists must be provided in flattened form\n",
    "        sep,dists = self.sep, self.batch.clone()\n",
    "        \n",
    "        dists*= self.complement_inv_beta_sigmoid[sep].expand(*dists.shape[:-1],-1)\n",
    "        dists+= self.inv_beta_sigmoid[sep].expand(*dists.shape[:-1],-1)\n",
    "        dists.logit_()\n",
    "        dists*= self.dist_std[sep].expand(*dists.shape[:-1],-1)\n",
    "        dists+= self.inv_beta[sep].expand(*dists.shape[:-1],-1)\n",
    "        \n",
    "        '''\n",
    "        dists*= self.complement_inv_beta_sigmoid[sep].repeat(*dists.shape[:-1],1)\n",
    "        dists+= self.inv_beta_sigmoid[sep].repeat(*dists.shape[:-1],1)\n",
    "        dists.logit_()\n",
    "        dists*= self.dist_std[sep].repeat(*dists.shape[:-1],1)\n",
    "        dists+= self.inv_beta[sep].repeat(*dists.shape[:-1],1)\n",
    "        '''\n",
    "        self.normalized = False\n",
    "        self.batch = dists\n",
    "    \n",
    "    def unnormalize_(self):#,batch=None,is_flat=None,return_original_dtype=True):\n",
    "\n",
    "        #if batch is not None:\n",
    "        #    self.set_data(batch,is_flat,return_original_dtype)\n",
    "\n",
    "        assert self.batch_seg_len <= self.seg_len, \\\n",
    "        f'mean/variance data insufficient for data with {self.batch_self_len} genomic bins.'\n",
    "        \n",
    "        if self.normalized: # Only perform these operations if the data is normalized\n",
    "            if self.is_flat: \n",
    "                self._unnormalize_(self.batch)\n",
    "            else:\n",
    "                # We must contend with the asymmetric data\n",
    "                batch = torch.empty_like(self.batch)\n",
    "                \n",
    "                i,j = torch.triu_indices(self.batch_seg_len,self.batch_seg_len,0)\n",
    "                b = self.batch\n",
    "                for ii,jj in [(i,j),(j,i)]: \n",
    "                        \n",
    "                    self.batch = b[...,ii,jj]\n",
    "                    self._unnormalize_()\n",
    "                    batch[...,ii,jj] = self.batch \n",
    "                self.batch = batch \n",
    "\n",
    "            self.normalized = False \n",
    "            \n",
    "        return self.unflatten()\n",
    "\n",
    "    def get_scHiC(self,threshold=2):\n",
    "\n",
    "        # Convert data to distances, unflatten, and compare to the threshold\n",
    "        return (self.unnormalize_() < threshold).to(self.batch_dtype)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4011b284-4e09-4d1e-89b3-2cbfeed5f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_folder='./results_large'\n",
    "if os.path.exists(save_folder): \n",
    "    milestone = 0 \n",
    "    for k in os.listdir(save_folder):\n",
    "        try: \n",
    "            n = int( k.split('-')[-1].split('.')[0] )\n",
    "            if n > milestone: \n",
    "                milestone = n\n",
    "        except:\n",
    "            pass\n",
    "    assert milestone > 0 # During testing\n",
    "    trainer.load(milestone=milestone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ccbdd0-4328-4a26-b594-28405010c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a2a924-fa96-40fa-8ba1-e53597f44e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load(milestone=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f5940-dd5b-48e3-aef2-51daec4e3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "embeddings = pd.read_pickle('../../data/embeddings/chrom_X.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0b1e16-bc33-4c57-b64f-d060c6861b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7058f6fe94f46b48f2d71697239f468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "emb = torch.stack(embeddings.iloc[:10,:].values.flatten().tolist(),dim=0).to(diffusion.device)\n",
    "trainer.model.eval()\n",
    "sample = trainer.model.sample(emb[:1,...].expand(10,-1,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd6539e4-35aa-442b-a9b8-a1d26d72f99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f139819aad0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample1 = DataProcessor(data=sample)\n",
    "scHiC_maps = sample1.get_scHiC()\n",
    "hic_map = scHiC_maps.mean(0)[0,...].cpu().numpy()\n",
    "plt.matshow(hic_map)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a20adbd-3780-4d12-8e31-dce3d1165d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5726387"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(config_ds.start_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "899a7b90-b813-4693-bc0f-4afae95a0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coord_idx</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Genomic_Index</th>\n",
       "      <th>embed_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, mat)</td>\n",
       "      <td>1</td>\n",
       "      <td>1420000</td>\n",
       "      <td>(1300000, 1, 1420000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, pat)</td>\n",
       "      <td>1</td>\n",
       "      <td>1420000</td>\n",
       "      <td>(1300000, 1, 1420000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(117823, mat)</td>\n",
       "      <td>1</td>\n",
       "      <td>1420000</td>\n",
       "      <td>(1300000, 1, 1420000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(117823, pat)</td>\n",
       "      <td>1</td>\n",
       "      <td>1420000</td>\n",
       "      <td>(1300000, 1, 1420000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(235660, pat)</td>\n",
       "      <td>1</td>\n",
       "      <td>1420000</td>\n",
       "      <td>(1300000, 1, 1420000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705642</th>\n",
       "      <td>(5771412, pat)</td>\n",
       "      <td>18</td>\n",
       "      <td>18380000</td>\n",
       "      <td>(1300000, 18, 18380000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705643</th>\n",
       "      <td>(5902103, pat)</td>\n",
       "      <td>18</td>\n",
       "      <td>18380000</td>\n",
       "      <td>(1300000, 18, 18380000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705643</th>\n",
       "      <td>(5902103, mat)</td>\n",
       "      <td>18</td>\n",
       "      <td>18380000</td>\n",
       "      <td>(1300000, 18, 18380000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705644</th>\n",
       "      <td>(6032851, mat)</td>\n",
       "      <td>18</td>\n",
       "      <td>18380000</td>\n",
       "      <td>(1300000, 18, 18380000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705644</th>\n",
       "      <td>(6032851, pat)</td>\n",
       "      <td>18</td>\n",
       "      <td>18380000</td>\n",
       "      <td>(1300000, 18, 18380000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11411290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              coord_idx Chromosome  Genomic_Index                embed_idx\n",
       "0              (0, mat)          1        1420000    (1300000, 1, 1420000)\n",
       "0              (0, pat)          1        1420000    (1300000, 1, 1420000)\n",
       "1         (117823, mat)          1        1420000    (1300000, 1, 1420000)\n",
       "1         (117823, pat)          1        1420000    (1300000, 1, 1420000)\n",
       "2         (235660, pat)          1        1420000    (1300000, 1, 1420000)\n",
       "...                 ...        ...            ...                      ...\n",
       "5705642  (5771412, pat)         18       18380000  (1300000, 18, 18380000)\n",
       "5705643  (5902103, pat)         18       18380000  (1300000, 18, 18380000)\n",
       "5705643  (5902103, mat)         18       18380000  (1300000, 18, 18380000)\n",
       "5705644  (6032851, mat)         18       18380000  (1300000, 18, 18380000)\n",
       "5705644  (6032851, pat)         18       18380000  (1300000, 18, 18380000)\n",
       "\n",
       "[11411290 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.index.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c06725-98b7-48ea-9185-c70fc7043595",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(dl) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec124e59-941a-4fa0-b12a-9f031dce2011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe9731c-1bca-4f5c-88e4-7568ee0d4e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 260, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31dc2d-2d5e-4869-9190-789d20cab39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0ab26e-5017-418d-96ab-13c732a0e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic attributes\n",
    "configs = config_ds\n",
    "embedded_regions = er\n",
    "shuffle = True#shuffle\n",
    "batch_size = 64#batch_size \n",
    "epoch = 0 \n",
    "internal_idx = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37b0044-1637-4a8d-85ac-0deb447cef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con, er = configs, embedded_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a30da0-7ab2-4d53-81c1-5b1c389d96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e69c55-9aa5-4bec-a38e-751b2aa5d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['coord_idx'] = con.start_indices # Starting position, first index position of con.coords\n",
    "df['Chromosome'] = ''\n",
    "df['Genomic_Index'] = con.genomic_index[con.start_indices] # Starting position, genomic index of chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4664b974-901b-4e9f-97f2-f80155c9fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df['coord_idx'] \n",
    "todo = np.ones(len(df),dtype=bool) # Saves some time with comparisons in the loop\n",
    "for _,row in con.coord_info.iterrows():\n",
    "    idx = todo & (s <= row['idx_max']) & (s >= row['idx_min'])\n",
    "    df.loc[idx,'Chromosome'] = row['Chromosome'] \n",
    "    todo&= ~idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e674c114-994a-4b52-b852-5506e3d64813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5726387"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fcbff13-1689-4d40-bebe-e29667113fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accession     GSE117876\n",
       "Organism          Human\n",
       "Cell_Type       GM12878\n",
       "Cell                 17\n",
       "Replicate             2\n",
       "Chromosome           22\n",
       "idx_min         6043075\n",
       "idx_max         6044756\n",
       "Name: 1034, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.coord_info.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf9ff603-4347-411f-8599-3daecefbd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(con.coord_info)): \n",
    "    assert con.coord_info['idx_min'].values[i] == con.coord_info['idx_max'].values[i-1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbf2fede-b05a-498c-9ce1-88f95c3cd533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6044757, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d69ec40-b357-4241-9094-d2aeb3183e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6857"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(con.start_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68784600-1bde-40e5-9068-4c8344a3f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Todo: For some reason, the fetch function returns an object size 2xNxN when two_channels=False and only\n",
    "one configuration is requested. \n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random \n",
    "\n",
    "def reduce_coord_info(coord_info,geos,organisms,cell_types,cell_numbers,chroms,replicates):\n",
    "    '''\n",
    "    Reduce the coord_info object to the rows that satisfy all desired restrictions. \n",
    "    '''\n",
    "\n",
    "    key_vals = {\n",
    "        'Accession':geos,\n",
    "        'Organism':organisms,\n",
    "        'Cell_Type':cell_types,\n",
    "        'Cell':cell_numbers,\n",
    "        'Replicate':replicates,\n",
    "        'Chromosome':chroms\n",
    "    }\n",
    "\n",
    "    for col, restrictions in key_vals.items():\n",
    "        assert len(coord_info) > 0, \"No data satisfies your desired restrictions.\"\n",
    "        if restrictions is None:\n",
    "            continue\n",
    "        idx = np.zeros(len(coord_info),dtype=bool)\n",
    "        vals = coord_info[col].values\n",
    "        for r in restrictions: \n",
    "            idx|= vals == r\n",
    "        idx = np.where(idx)[0]\n",
    "        coord_info = coord_info.iloc[idx]\n",
    "\n",
    "    # Reset the index in the coord_info DataFrame to make indexing it later more straightforward. \n",
    "    coord_info.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return coord_info \n",
    "\n",
    "def load_coords(filepath,coord_info):\n",
    "\n",
    "    index_ranges = [[coord_info['idx_min'].iloc[0],coord_info['idx_max'].iloc[0]+1]]\n",
    "    for k,row in coord_info.iterrows(): \n",
    "        if k == 0:\n",
    "            continue\n",
    "        if index_ranges[-1][1] == row['idx_min']:\n",
    "            index_ranges[-1][1] = row['idx_max']+1\n",
    "        else: \n",
    "            index_ranges.append([row['idx_min'],row['idx_max']+1])\n",
    "\n",
    "    data = []\n",
    "    for range in index_ranges: \n",
    "        data.append(\n",
    "            pd.read_hdf(\n",
    "                filepath,\n",
    "                key='Coordinates',\n",
    "                start=range[0],\n",
    "                stop=range[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    data = pd.concat(\n",
    "        data,\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    )\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_valid_starts(permitted_lengths,segment_length,allow_overlap=False): \n",
    "        '''\n",
    "        Find all indices where, including that bead, there are segment_length\n",
    "        sequential beads in a row (i.e. not removed during Dip-C clean process)\n",
    "\n",
    "        If allow_overlap is set to False, the indices returned will represent\n",
    "        the starting points for non-overlapping regions only\n",
    "        '''\n",
    "\n",
    "        pl = permitted_lengths \n",
    "    \n",
    "        # If overlapping regions are fine, simply need segments long enough\n",
    "        # to satisfy the following \n",
    "        if allow_overlap:\n",
    "            return pl[pl > segment_length-2]\n",
    "\n",
    "        # A monomer at the extreme end of one segment can appear as the start of the next \n",
    "        # segment per this setup \n",
    "        perlens_for_no_overlap = np.arange(segment_length-1,pl.max()+.5,segment_length-1)\n",
    "        perlens_for_no_overlap = perlens_for_no_overlap.reshape(1,len(perlens_for_no_overlap))\n",
    "\n",
    "        pl = pl.reshape(len(pl),1)\n",
    "        return np.where( (pl == perlens_for_no_overlap).any(1) )[0]\n",
    "\n",
    "def reset_coord_info_indices(coord_info):\n",
    "    \n",
    "    # Make the indices match the DataFrame containing actual coordinates \n",
    "    coord_info.loc[0,'idx_max'] = coord_info.loc[0,'idx_max'] - coord_info.loc[0,'idx_min']\n",
    "    coord_info.loc[0,'idx_min'] = 0 \n",
    "    for i in range(1,len(coord_info)):\n",
    "        length = coord_info.loc[i,'idx_max'] - coord_info.loc[i,'idx_min']\n",
    "        coord_info.loc[i,'idx_min'] = coord_info.loc[i-1,'idx_max'] + 1\n",
    "        coord_info.loc[i,'idx_max'] = coord_info.loc[i,'idx_min'] + length\n",
    "\n",
    "    return coord_info\n",
    "\n",
    "class ConfigDataset:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath,\n",
    "        segment_length=64,\n",
    "        batch_size=64,\n",
    "        normalize_distances=True,\n",
    "        geos=None,\n",
    "        organisms=None,\n",
    "        cell_types=None,\n",
    "        cell_numbers=None,\n",
    "        chroms=None,\n",
    "        replicates=None,\n",
    "        shuffle=True,\n",
    "        allow_overlap=False,\n",
    "        two_channels=False,\n",
    "        try_GPU=True,\n",
    "        mean_dist_fp='../../data/mean_dists.pt',\n",
    "        mean_sq_dist_fp='../../data/squares.pt'\n",
    "    ):\n",
    "        '''\n",
    "        filepath: Dataset location. Should be formatted as designed for this study\n",
    "        segment_length: The number of monomers relevant to the distance maps \n",
    "        batch_size: Number of configurations per batch \n",
    "        shuffle: Should the sample indices be shuffled before each epoch? \n",
    "        allow_overlap: Can the dataset include overlapping regions (True), \n",
    "                       or should they all be fully independent (False)? \n",
    "        two_channels: Does the data include the maternal & paternal structures\n",
    "                        in the same sample (two channels of the image)? Otherwise, \n",
    "                        returns one or the other. \n",
    "\n",
    "        To choose a subset of the overall dataset, use the following variables. In all cases, \n",
    "        a value of None means no restriction on this parameter. Otherwise, a list of those \n",
    "        parameters to be INCLUDED should be provided. \n",
    "            1. geos: GEO accession numbers\n",
    "            2. organisms: Organism, e.g. 'Human' or 'Mouse'\n",
    "            3. cell_types: Cell type \n",
    "            4. cell_numbers: Cell number within a dataset specified above. Should be np.int64\n",
    "            5. chroms: Chromosomes. Should be passed as a string. \n",
    "            6. replicates: Replicates from Dip-C procedure on the same cell's data\n",
    "        '''\n",
    "\n",
    "        # Assign qualities where relevant \n",
    "        filepath = filepath \n",
    "        seg_len = segment_length \n",
    "        batch_size = batch_size\n",
    "        shuffle = shuffle\n",
    "        allow_overlap = allow_overlap\n",
    "        two_channels = two_channels\n",
    "        norm_dists = normalize_distances\n",
    "\n",
    "        # torch.cuda.is_available() doesn't work properly on \n",
    "        # SuperCloud, so use this approach instead. \n",
    "        try: \n",
    "            assert try_GPU\n",
    "            device = torch.empty(1).cuda().device\n",
    "        except:\n",
    "            device = torch.empty(1).device\n",
    "\n",
    "        # Load the information object to help us decide which portion of the dataset to load from storage\n",
    "        coord_info = pd.read_hdf(\n",
    "            filepath,\n",
    "            key='coord_info'\n",
    "        )\n",
    "\n",
    "        # Find the indices to load from memory\n",
    "        coord_info = reduce_coord_info(coord_info,geos,organisms,cell_types,cell_numbers,chroms,replicates)\n",
    "\n",
    "        # Fetch the desired rows from memory\n",
    "        coord_df = load_coords(filepath,coord_info)\n",
    "\n",
    "        # Place information from the coord_df object into objects which improve speed downstream \n",
    "        coords = torch.from_numpy(coord_df[['mat_x','mat_y','mat_z','pat_x','pat_y','pat_z']].values).to(torch.double)\n",
    "        genomic_index = coord_df['Genomic_Index'].values\n",
    "\n",
    "        # Get the indices of valid starting positions to obtain uninterrupted regions of the referenced dimensions\n",
    "        start_indices = get_valid_starts(coord_df['Permitted_Lengths'].values,segment_length,allow_overlap)\n",
    "\n",
    "        # Set the indices of the coord_info object to match the loaded dataset\n",
    "        coord_info = reset_coord_info_indices(coord_info)\n",
    "\n",
    "        # Track the sample indices. This can be shuffled without perturbing the main dataset \n",
    "        #data_index = \n",
    "        if two_channels: \n",
    "            data_index = start_indices\n",
    "        else: \n",
    "            n = len(start_indices)\n",
    "            data_index = np.empty((2*n,2),dtype=np.int64)\n",
    "            data_index[:n,0] = start_indices # Rows in coords object\n",
    "            data_index[:n,1] = 0 # Maternal is in columns 0,1,2\n",
    "            data_index[n:,0] = start_indices \n",
    "            data_index[n:,1] = 3 # Paternal is in columns 3,4,5\n",
    "\n",
    "        # Define some internal indexing objects to keep track of the dataset\n",
    "        epoch = 0     # Which epoch are we on? \n",
    "        inner_idx = 0 # Keep track of which row in the dataset we're considering\n",
    "        reset_index() # This will shuffle the index (if desired) and increase epoch to 1\n",
    "        triu_indices = torch.triu_indices(segment_length,segment_length,1) \n",
    "\n",
    "        # The following is used to index the distance objects, which are indexed such that\n",
    "        # sep[i] corresponds to i+1, so subtract the 1\n",
    "        sep_idx = triu_indices[1] - triu_indices[0] - 1  \n",
    "        \n",
    "\n",
    "        # Initialize some objects used during batch fetching/manipulation\n",
    "        batch_coords = torch.empty(batch_size,seg_len,3*(1+int(two_channels)),\n",
    "                                        device=device,dtype=coords.dtype)\n",
    "        batch_dists = torch.empty(batch_size,1+int(two_channels),seg_len-1,seg_len-1,\n",
    "                                      device=device,dtype=torch.float)\n",
    "\n",
    "        # Load the distance vs genomic separation relationships used to normalize the distance data\n",
    "        # for use in the signmoid mod. Afterwards, process the values we use at each iteration\n",
    "        dt = batch_coords.dtype\n",
    "        mean_dist = torch.load(mean_dist_fp,map_location=device).flatten()[:seg_len].to(dt)\n",
    "        mean_square_dist = torch.load(mean_sq_dist_fp,map_location=device).flatten()[:seg_len].to(dt)\n",
    "        dist_std = (mean_square_dist - mean_dist**2).sqrt()\n",
    "        inv_beta = torch.sqrt( 2*mean_square_dist/3 )\n",
    "        inv_beta_sigmoid = torch.sigmoid( -inv_beta/dist_std )\n",
    "        complement_inv_beta_sigmoid = 1 - inv_beta_sigmoid\n",
    "\n",
    "    def reset_index(self):\n",
    "\n",
    "        if shuffle: \n",
    "            n_unused = len(self) - inner_idx\n",
    "            if n_unused > 0 and n_unused < batch_size: \n",
    "                # Place the unused data at the front, if the epoch\n",
    "                # hasn't *totally* completed but is less than a \n",
    "                # batch length away. \n",
    "                temp = data_index[-n_unused:,...].copy()\n",
    "                idx = np.arange(len(self)-n_unused)\n",
    "                data_index[n_unused:,...] = data_index[idx,...]\n",
    "                data_index[:n_unused,...] = temp \n",
    "            else:\n",
    "                idx = np.arange(data_index.shape[0])\n",
    "                random.shuffle(idx)\n",
    "                data_index = data_index[idx,...]\n",
    "\n",
    "        epoch+=1\n",
    "        inner_idx = 0\n",
    "\n",
    "    def normalize_dists(self,dists):\n",
    "        if not norm_dists:\n",
    "            return dists\n",
    "        sep = sep_idx\n",
    "        i,j = triu_indices\n",
    "        bs = dists.shape[0] #batch_size\n",
    "        j = j-1\n",
    "        dists-= inv_beta[sep].repeat(bs,1) # Should eventually replace with expand to save memory \n",
    "        dists/= dist_std[sep].repeat(bs,1)\n",
    "        dists.sigmoid_()\n",
    "        dists-= inv_beta_sigmoid[sep].repeat(bs,1)\n",
    "        dists/= complement_inv_beta_sigmoid[sep].repeat(bs,1)\n",
    "        return dists \n",
    "\n",
    "    def get_genomic_regions(self):\n",
    "    \n",
    "        coord_info = coord_info\n",
    "        start_indices = start_indices\n",
    "        gen_idx = genomic_index\n",
    "        nbeads = seg_len\n",
    "    \n",
    "        regions = pd.DataFrame({\n",
    "            'Start':gen_idx[start_indices]\n",
    "        })\n",
    "        regions['Stop'] = regions['Start'] + (gen_idx[start_indices[0]+1]- gen_idx[start_indices[0]]) * seg_len\n",
    "        regions.insert(0,'Chromosome','')\n",
    "    \n",
    "        for _,row in coord_info.iterrows():\n",
    "            idx = (start_indices >= row['idx_min']) & (start_indices <= row['idx_max'])\n",
    "            if idx.any(): \n",
    "                regions.loc[idx,'Chromosome'] = row['Chromosome']\n",
    "    \n",
    "        regions.drop_duplicates(ignore_index=True,inplace=True)\n",
    "        \n",
    "        return regions\n",
    "\n",
    "    def fetch_coords(self,start_idx): \n",
    "        \n",
    "        if type(start_idx) == tuple: \n",
    "            #assert start[1] in ['mat','pat']\n",
    "            y = start_idx[0]\n",
    "            x_idxs = [3*(start_idx[1] == 'pat')]\n",
    "        else:\n",
    "            y = start_idx\n",
    "            x_idxs = [0,3] \n",
    "\n",
    "        coords = []\n",
    "        for x_idx in x_idxs: \n",
    "            coords.append(coords[y:y+seg_len,x_idx:x_idx+3])\n",
    "\n",
    "        return torch.stack(coords,dim=0)\n",
    "            \n",
    "\n",
    "    def fetch(self,start_indices):\n",
    "\n",
    "        # Get the relevant coordinates\n",
    "        if type(start_indices) == int or type(start_indices) == tuple: \n",
    "            start_indices = [start_indices]\n",
    "\n",
    "        coords = torch.stack([fetch_coords(i) for i in start_indices],dim=0).to(device)\n",
    "\n",
    "        # Compute distances; ignore duplicates\n",
    "        i,j = triu_indices\n",
    "        dists = torch.cdist(coords,coords)[...,i,j]\n",
    "\n",
    "        # Normalize distances (if desired) \n",
    "        if norm_dists: \n",
    "            s = dists.shape\n",
    "            dists = normalize_dists(dists.flatten(0,-2)).to(batch_dists.dtype).reshape(s)\n",
    "\n",
    "        b,c,h = dists.shape[0],dists.shape[1],seg_len-1\n",
    "        batch = torch.empty((b,c,h,h),dtype=torch.float,device=device)\n",
    "        j = j-1\n",
    "        batch[:,:,i,j] = dists.to(torch.float)\n",
    "        batch[:,:,j,i] = dists.to(torch.float)\n",
    "        \n",
    "        return batch \n",
    "    \n",
    "    def __len__(self):\n",
    "        return data_index.shape[0]\n",
    "    \n",
    "    def __next__(self):\n",
    "\n",
    "        # Avoid out of range issues\n",
    "        if inner_idx + batch_size >= len(self):\n",
    "            reset_index()\n",
    "\n",
    "        # Get the section of the main dataset we're pulling from \n",
    "        idx = data_index[inner_idx:inner_idx+batch_size,...]\n",
    "        \n",
    "        # Get the distance map associated with the inquired regions\n",
    "        if two_channels:\n",
    "            batch_coords[:] = coords[idx,:].to(device).reshape_as(batch_coords)\n",
    "        else:\n",
    "            for i in range(batch_size):\n",
    "                i0 = idx[i,0]\n",
    "                i1 = idx[i,1]\n",
    "                batch_coords[i,:,:] = coords[i0:i0+seg_len,i1:i1+3]\n",
    "                #batch_coords[sub_idx,i,:] = coords[idx[sub_idx,0],:3].to(device).reshape_as(batch_coords[sub_idx,:,:])\n",
    "                #sub_idx^= True # Flips to paternal index\n",
    "                #batch_coords[sub_idx,i,:] = coords[idx[sub_idx,0],3:].to(device).reshape_as(batch_coords[sub_idx,:,:])\n",
    "\n",
    "        i,j = triu_indices\n",
    "        for k in range(batch_dists.shape[1]):\n",
    "            ii = 3*k\n",
    "            jj = ii+3\n",
    "            dists = torch.cdist(batch_coords[:,:,ii:jj],batch_coords[:,:,ii:jj])[:,i,j]\n",
    "            batch_dists[:,k,i,j-1] = normalize_dists(dists).to(batch_dists.dtype) \n",
    "        batch_dists[:,:,j-1,i] = batch_dists[:,:,i,j-1]\n",
    "\n",
    "        inner_idx+= batch_size \n",
    "\n",
    "        return batch_dists \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "215680b2-802f-4399-baeb-2e5c67013ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/processed_data.hdf5'\n",
    "segment_length=64\n",
    "batch_size=64\n",
    "normalize_distances=True\n",
    "geos=None\n",
    "organisms=None\n",
    "cell_types=None\n",
    "cell_numbers=None\n",
    "chroms=[f'{k}' for k in range(1,23)]#None\n",
    "replicates=None\n",
    "shuffle=True\n",
    "allow_overlap=True#False\n",
    "two_channels=False\n",
    "try_GPU=True\n",
    "mean_dist_fp='../../data/mean_dists.pt'\n",
    "mean_sq_dist_fp='../../data/squares.pt'\n",
    "\n",
    "# Assign qualities where relevant \n",
    "filepath = filepath \n",
    "seg_len = segment_length \n",
    "batch_size = batch_size\n",
    "shuffle = shuffle\n",
    "allow_overlap = allow_overlap\n",
    "two_channels = two_channels\n",
    "norm_dists = normalize_distances\n",
    "\n",
    "# torch.cuda.is_available() doesn't work properly on \n",
    "# SuperCloud, so use this approach instead. \n",
    "try: \n",
    "    assert try_GPU\n",
    "    device = torch.empty(1).cuda().device\n",
    "except:\n",
    "    device = torch.empty(1).device\n",
    "\n",
    "coord_info = pd.read_hdf(\n",
    "    filepath,\n",
    "    key='coord_info'\n",
    ")\n",
    "\n",
    "# Find the indices to load from memory\n",
    "coord_info = reduce_coord_info(coord_info,geos,organisms,cell_types,cell_numbers,chroms,replicates)\n",
    "\n",
    "# Fetch the desired rows from memory\n",
    "coord_df = load_coords(filepath,coord_info)\n",
    "\n",
    "# Place information from the coord_df object into objects which improve speed downstream \n",
    "coords = torch.from_numpy(coord_df[['mat_x','mat_y','mat_z','pat_x','pat_y','pat_z']].values).to(torch.double)\n",
    "genomic_index = coord_df['Genomic_Index'].values\n",
    "\n",
    "# Get the indices of valid starting positions to obtain uninterrupted regions of the referenced dimensions\n",
    "start_indices = get_valid_starts(coord_df['Permitted_Lengths'].values,segment_length,allow_overlap)\n",
    "\n",
    "# Set the indices of the coord_info object to match the loaded dataset\n",
    "coord_info = reset_coord_info_indices(coord_info)\n",
    "\n",
    "# Track the sample indices. This can be shuffled without perturbing the main dataset \n",
    "#data_index = \n",
    "if two_channels: \n",
    "    data_index = start_indices\n",
    "else: \n",
    "    n = len(start_indices)\n",
    "    data_index = np.empty((2*n,2),dtype=np.int64)\n",
    "    data_index[:n,0] = start_indices # Rows in coords object\n",
    "    data_index[:n,1] = 0 # Maternal is in columns 0,1,2\n",
    "    data_index[n:,0] = start_indices \n",
    "    data_index[n:,1] = 3 # Paternal is in columns 3,4,5\n",
    "\n",
    "# Define some internal indexing objects to keep track of the dataset\n",
    "epoch = 0     # Which epoch are we on? \n",
    "inner_idx = 0 # Keep track of which row in the dataset we're considering\n",
    "'''\n",
    "reset_index() # This will shuffle the index (if desired) and increase epoch to 1\n",
    "triu_indices = torch.triu_indices(segment_length,segment_length,1) \n",
    "\n",
    "# The following is used to index the distance objects, which are indexed such that\n",
    "# sep[i] corresponds to i+1, so subtract the 1\n",
    "sep_idx = triu_indices[1] - triu_indices[0] - 1  \n",
    "\n",
    "\n",
    "# Initialize some objects used during batch fetching/manipulation\n",
    "batch_coords = torch.empty(batch_size,seg_len,3*(1+int(two_channels)),\n",
    "                                device=device,dtype=coords.dtype)\n",
    "batch_dists = torch.empty(batch_size,1+int(two_channels),seg_len-1,seg_len-1,\n",
    "                              device=device,dtype=torch.float)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5c6dd1a-1857-4fe8-8734-eb5d22c05087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genomic_Index</th>\n",
       "      <th>mat_x</th>\n",
       "      <th>mat_y</th>\n",
       "      <th>mat_z</th>\n",
       "      <th>pat_x</th>\n",
       "      <th>pat_y</th>\n",
       "      <th>pat_z</th>\n",
       "      <th>Permitted_Lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420000</td>\n",
       "      <td>0.791378</td>\n",
       "      <td>10.994729</td>\n",
       "      <td>-13.188290</td>\n",
       "      <td>15.056885</td>\n",
       "      <td>25.921054</td>\n",
       "      <td>-9.564357</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1440000</td>\n",
       "      <td>-0.268241</td>\n",
       "      <td>10.520088</td>\n",
       "      <td>-13.089626</td>\n",
       "      <td>15.796097</td>\n",
       "      <td>26.579920</td>\n",
       "      <td>-8.861701</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460000</td>\n",
       "      <td>-1.385308</td>\n",
       "      <td>10.551379</td>\n",
       "      <td>-13.144014</td>\n",
       "      <td>16.901122</td>\n",
       "      <td>25.803865</td>\n",
       "      <td>-8.955327</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1480000</td>\n",
       "      <td>-1.559841</td>\n",
       "      <td>11.434083</td>\n",
       "      <td>-13.602630</td>\n",
       "      <td>15.759492</td>\n",
       "      <td>25.506422</td>\n",
       "      <td>-9.133084</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500000</td>\n",
       "      <td>-0.770992</td>\n",
       "      <td>11.475849</td>\n",
       "      <td>-14.588114</td>\n",
       "      <td>15.564120</td>\n",
       "      <td>24.792415</td>\n",
       "      <td>-9.853877</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044752</th>\n",
       "      <td>51120000</td>\n",
       "      <td>-11.972702</td>\n",
       "      <td>-3.085614</td>\n",
       "      <td>-9.673203</td>\n",
       "      <td>17.225127</td>\n",
       "      <td>22.440735</td>\n",
       "      <td>-22.862289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044753</th>\n",
       "      <td>51140000</td>\n",
       "      <td>-12.182970</td>\n",
       "      <td>-2.963733</td>\n",
       "      <td>-9.538029</td>\n",
       "      <td>16.155504</td>\n",
       "      <td>21.897527</td>\n",
       "      <td>-22.852975</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044754</th>\n",
       "      <td>51160000</td>\n",
       "      <td>-12.197024</td>\n",
       "      <td>-3.417248</td>\n",
       "      <td>-10.873362</td>\n",
       "      <td>16.484580</td>\n",
       "      <td>21.569925</td>\n",
       "      <td>-22.061780</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044755</th>\n",
       "      <td>51180000</td>\n",
       "      <td>-12.326706</td>\n",
       "      <td>-3.461102</td>\n",
       "      <td>-11.097408</td>\n",
       "      <td>17.561667</td>\n",
       "      <td>21.617942</td>\n",
       "      <td>-21.400754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044756</th>\n",
       "      <td>51200000</td>\n",
       "      <td>-13.517688</td>\n",
       "      <td>-3.471649</td>\n",
       "      <td>-11.781557</td>\n",
       "      <td>17.498822</td>\n",
       "      <td>22.066643</td>\n",
       "      <td>-22.683708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6044757 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Genomic_Index      mat_x      mat_y      mat_z      pat_x      pat_y  \\\n",
       "0              1420000   0.791378  10.994729 -13.188290  15.056885  25.921054   \n",
       "1              1440000  -0.268241  10.520088 -13.089626  15.796097  26.579920   \n",
       "2              1460000  -1.385308  10.551379 -13.144014  16.901122  25.803865   \n",
       "3              1480000  -1.559841  11.434083 -13.602630  15.759492  25.506422   \n",
       "4              1500000  -0.770992  11.475849 -14.588114  15.564120  24.792415   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "6044752       51120000 -11.972702  -3.085614  -9.673203  17.225127  22.440735   \n",
       "6044753       51140000 -12.182970  -2.963733  -9.538029  16.155504  21.897527   \n",
       "6044754       51160000 -12.197024  -3.417248 -10.873362  16.484580  21.569925   \n",
       "6044755       51180000 -12.326706  -3.461102 -11.097408  17.561667  21.617942   \n",
       "6044756       51200000 -13.517688  -3.471649 -11.781557  17.498822  22.066643   \n",
       "\n",
       "             pat_z  Permitted_Lengths  \n",
       "0        -9.564357                574  \n",
       "1        -8.861701                573  \n",
       "2        -8.955327                572  \n",
       "3        -9.133084                571  \n",
       "4        -9.853877                570  \n",
       "...            ...                ...  \n",
       "6044752 -22.862289                  4  \n",
       "6044753 -22.852975                  3  \n",
       "6044754 -22.061780                  2  \n",
       "6044755 -21.400754                  1  \n",
       "6044756 -22.683708                  0  \n",
       "\n",
       "[6044757 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7d0b6c0-a172-4555-a6c6-31c1a6ba8af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5730736"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06c7822d-1782-4b0f-8d78-64ad3a14eee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6858"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(start_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cef5c2d0-c2d3-4f45-a668-a67c3c83f256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([574, 573, 572, ...,  66,  65,  64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_ds.start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4144e-3b93-4e83-92d2-38fb909b948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the relevant information from con into a DataFrame for easy manipulation/\n",
    "df = pd.DataFrame()\n",
    "df['coord_idx'] = con.start_indices # Starting position, first index position of con.coords\n",
    "df['Chromosome'] = ''\n",
    "df['Genomic_Index'] = con.genomic_index[con.start_indices] # Starting position, genomic index of chromosome\n",
    "\n",
    "# Fill in the chromosome position\n",
    "s = df['coord_idx'] \n",
    "todo = np.ones(len(df),dtype=bool) # Saves some time with comparisons in the loop\n",
    "for _,row in con.coord_info.iterrows():\n",
    "    idx = todo & (s <= row['idx_max']) & (s >= row['idx_min'])\n",
    "    df.loc[idx,'Chromosome'] = row['Chromosome'] \n",
    "    todo&= ~idx\n",
    "\n",
    "# Handle the EmbeddedRegions object's indices, if it exists\n",
    "if er is not None: \n",
    "    # Place the data in a DataFrame for easy comparison with the configuration data\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['Chromosome'] = er.chrom_index.values\n",
    "    df2['Genomic_Index'] = er.genomic_index.values\n",
    "\n",
    "    # Free memory by dropping the unused embeddings\n",
    "    if drop_unmatched_pairs: \n",
    "        #drop_idx = er.index[df.merge(df2,indicator=True,how='right')['_merge'] == 'right_only']\n",
    "        drop_idx = df2.merge(df,indicator=True,how='left')\n",
    "        drop_idx = drop_idx[ drop_idx['_merge'].values == 'left_only' ][['Chromosome','Genomic_Index']].drop_duplicates()\n",
    "        drop_idx = [(er.length_index[0],*drop_idx.iloc[i].values) for i in range(len(drop_idx))]\n",
    "        embedded_regions.drop(index=drop_idx) # Pretty sure we can just do er.drop, but pointer vs not always gets me...\n",
    "        del drop_idx\n",
    "\n",
    "    # This reduces our choices to the regions present in both objects \n",
    "    df = df.merge(df2,how='inner')\n",
    "    del df2\n",
    "\n",
    "    # Get the index for embedding\n",
    "    length = er.length_index[0]\n",
    "    embed_idx = np.array([\n",
    "        [length for k in range(len(df))],\n",
    "        df['Chromosome'].values,\n",
    "        df['Genomic_Index'].values\n",
    "    ]).T\n",
    "    df['embed_idx'] = pd.MultiIndex.from_tuples(\n",
    "        list(map(tuple,embed_idx)),\n",
    "        names=list(er.index.names)\n",
    "    )\n",
    "    del embed_idx\n",
    "\n",
    "if not con.two_channels: \n",
    "    # Must account for maternal vs paternal copies/duplicates\n",
    "    idx1 = df['coord_idx'].values\n",
    "    coord_idx = [(i,'mat') for i in idx1]\n",
    "    coord_idx.extend([(i,'pat') for i in idx1])\n",
    "    df = pd.concat([df,df])\n",
    "    df['coord_idx'] = coord_idx\n",
    "    del coord_idx \n",
    "\n",
    "# Finally, make the index an attribute of this object and \n",
    "# shuffle the index for the first epoch (if desired). \n",
    "index = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231703b-a1bb-46ef-ac26-887be83004b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe8c69-5d42-440e-80b8-5a37052e31d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b0446-18ea-4c78-9983-9c5dc3cccc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d12ad-0217-43b5-baf8-7429a1fd5ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc825b26-c0ae-499f-bb3b-57b14e5a77a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad34829-52f8-47e6-916e-1b629f685955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c312b9a-79fb-4f3b-9069-25253ea28e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed1b24-de17-48d3-afa9-713f9d7bed36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f304fe0-bcde-4fde-86e0-47cc6a5d9083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0875f-262d-4f35-aaab-1b56f8e6a65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded28a3-4098-45a6-91eb-f046c1beaaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
