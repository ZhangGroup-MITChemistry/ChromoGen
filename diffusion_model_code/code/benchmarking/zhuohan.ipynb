{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf878035-2e20-4946-9900-0bd8749c06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import os, pickle, time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler,Dataset\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from scipy.sparse import load_npz,csr_matrix,save_npz\n",
    "import subprocess\n",
    "from torch.nn import MultiheadAttention\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "'''\n",
    "_________________________\n",
    "Necessary shit Zhuohan didn't include in the file\n",
    "_________________________\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "\n",
    "def pad_signal_matrix(matrix, pad_len=300):\n",
    "    paddings = np.zeros(pad_len).astype('float32')\n",
    "    dmatrix = np.vstack((paddings, matrix[:, -pad_len:]))[:-1, :]\n",
    "    umatrix = np.vstack((matrix[:, :pad_len], paddings))[1:, :]\n",
    "    return np.hstack((dmatrix, matrix, umatrix))\n",
    "\n",
    "'''\n",
    "_________________________\n",
    "Prepare the data\n",
    "_________________________\n",
    "'''\n",
    "\n",
    "def pad_seq_matrix(matrix, pad_len=300):\n",
    "    paddings = np.zeros((1, 4, pad_len)).astype('int8')\n",
    "    dmatrix = np.concatenate((paddings, matrix[:, :, -pad_len:]), axis=0)[:-1, :, :]\n",
    "    umatrix = np.concatenate((matrix[:, :, :pad_len], paddings), axis=0)[1:, :, :] # WTF\n",
    "    return np.concatenate((dmatrix, matrix, umatrix), axis=2)\n",
    "\n",
    "def load_ref_genome(chr):\n",
    "    #ref_path = 'Your Path'\n",
    "    #ref_file = os.path.join(ref_path, 'Your File')\n",
    "    #ref_file = '/home/gridsan/gschuette/binz_group_shared/zlao/data/hg38/chr1.fa'\n",
    "    ref_file = '/home/gridsan/gschuette/binz_group_shared/zlao/data/hg38/chr1.npz'\n",
    "    ref_gen_data = load_npz(ref_file).toarray().reshape(4, -1, 1000).swapaxes(0, 1)\n",
    "    return torch.tensor(pad_seq_matrix(ref_gen_data))\n",
    "\n",
    "def load_dnase(dnase_seq):\n",
    "    dnase_seq = np.expand_dims(pad_signal_matrix(dnase_seq.reshape(-1, 1000)), axis=1)\n",
    "    return torch.tensor(dnase_seq)\n",
    "\n",
    "def prepare_train_data(cl,chrs):\n",
    "    dnase_data={}\n",
    "    ref_data={}\n",
    "    #dnase_path = 'Your Path'\n",
    "    #with open(dnase_path + 'Your File', 'rb') as f:\n",
    "    with open('/home/gridsan/gschuette/binz_group_shared/zlao/data/GM12878_dnase.pickle','rb') as f:\n",
    "        dnase = pickle.load(f)\n",
    "    dnase_seq = dnase[chrs]\n",
    "\n",
    "    dnase_data[chrs]=load_dnase(dnase_seq.toarray())\n",
    "    ref_data[chrs]=load_ref_genome(chrs)\n",
    "    return dnase_data, ref_data\n",
    "\n",
    "def load_data(data,ref_data,dnase_data):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    args = get_args()\n",
    "    data=data.numpy().astype(int)\n",
    "    input=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        chr = args.curr_chr\n",
    "        s,e=data[i][1],data[i][2]\n",
    "        input.append(torch.cat((ref_data[chr][s:e],dnase_data[chr][s:e]),dim=1))\n",
    "\n",
    "    input= torch.stack(input)\n",
    "\n",
    "    return input.float().to(device)\n",
    "\n",
    "'''\n",
    "_______________________\n",
    "Model details (backbone + transformer encode + dimension reduction)\n",
    "_______________________\n",
    "'''\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        conv_kernel_size1 = 10\n",
    "        conv_kernel_size2 = 8\n",
    "        pool_kernel_size1 = 5\n",
    "        pool_kernel_size2 = 4\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv1d(5, 256, kernel_size=conv_kernel_size1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv1d(256, 256, kernel_size=conv_kernel_size1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=pool_kernel_size1, stride=pool_kernel_size1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv1d(256, 360, kernel_size=conv_kernel_size2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv1d(360, 360, kernel_size=conv_kernel_size2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=pool_kernel_size2, stride=pool_kernel_size2),\n",
    "            nn.BatchNorm1d(360),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv1d(360, 512, kernel_size=conv_kernel_size2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(512, 512, kernel_size=conv_kernel_size2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.2))\n",
    "        self.num_channels = 512\n",
    "    def forward(self, x):\n",
    "        out = self.conv_net(x)\n",
    "        return out\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    if activation == \"gelu\":\n",
    "        return F.gelu\n",
    "    if activation == \"glu\":\n",
    "        return F.glu\n",
    "    raise RuntimeError(F\"activation should be relu/gelu, not {activation}.\")\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n",
    "                 activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n",
    "        return tensor if pos is None else tensor + pos\n",
    "    def forward(self, src,\n",
    "                    src_mask: Optional[Tensor] = None,\n",
    "                    src_key_padding_mask: Optional[Tensor] = None,\n",
    "                    pos: Optional[Tensor] = None):\n",
    "        src2 = self.norm1(src)\n",
    "        q = k = self.with_pos_embed(src2, pos)\n",
    "        src2 = self.self_attn(q, k, value=src2, attn_mask=src_mask,\n",
    "                              key_padding_mask=src_key_padding_mask)[0]\n",
    "        src = src + self.dropout1(src2)\n",
    "        src2 = self.norm2(src)\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        return src\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super().__init__()\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "    def forward(self, src,\n",
    "                mask: Optional[Tensor] = None,\n",
    "                src_key_padding_mask: Optional[Tensor] = None,\n",
    "                pos: Optional[Tensor] = None):\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask, pos=pos)\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "        return output\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=8, num_encoder_layers=6,\n",
    "                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1,\n",
    "                 activation=\"relu\"\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        if num_decoder_layers > 0:\n",
    "            encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward,\n",
    "                                                    dropout, activation)\n",
    "            encoder_norm = nn.LayerNorm(d_model)\n",
    "            self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
    "\n",
    "        self._reset_parameters()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, pos_embed=None, mask=None):\n",
    "        src = src.permute(2, 0, 1)\n",
    "        print('transformer_input', src.shape)\n",
    "        if mask is not None:\n",
    "            mask = mask.flatten(1)\n",
    "        memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)\n",
    "        return memory.transpose(0,1)\n",
    "\n",
    "class AttentionPool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.pool_fn = Rearrange('b (n p) d-> b n p d', n=1)\n",
    "        self.to_attn_logits = nn.Parameter(torch.eye(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_logits = einsum('b n d, d e -> b n e', x, self.to_attn_logits)\n",
    "        x = self.pool_fn(x)\n",
    "        logits = self.pool_fn(attn_logits)\n",
    "\n",
    "        attn = logits.softmax(dim = -2)\n",
    "        return (x * attn).sum(dim = -2).squeeze()\n",
    "\n",
    "class Tranmodel(nn.Module):\n",
    "    def __init__(self, backbone, transfomer, bins=200, max_bin=10, in_dim=64):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.transformer = transfomer\n",
    "        hidden_dim = transfomer.d_model\n",
    "        self.input_proj = nn.Conv1d(backbone.num_channels, hidden_dim, kernel_size=1)\n",
    "        self.bins=bins\n",
    "        self.max_bin=max_bin\n",
    "        self.attention_pool = AttentionPool(hidden_dim)\n",
    "        self.project=nn.Sequential(\n",
    "            Rearrange('(b n) c -> b c n', n=bins*5),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=15, padding=7,groups=hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Conv1d(hidden_dim, embed_dim, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.cnn=nn.Sequential(\n",
    "            nn.Conv1d(embed_dim, embed_dim, kernel_size=15, padding=7),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.MaxPool1d(kernel_size=5, stride=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(embed_dim, embed_dim, kernel_size=1),\n",
    "            nn.Dropout(0.2),\n",
    "            Rearrange('b c n -> b n c')\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        input=rearrange(input,'b n c l -> (b n) c l')\n",
    "        src = self.backbone(input)\n",
    "        src = self.input_proj(src)\n",
    "        src = self.transformer(src)\n",
    "        src = self.attention_pool(src)\n",
    "        src = self.project(src)\n",
    "        src = self.cnn(src)\n",
    "        return src\n",
    "\n",
    "def build_backbone():\n",
    "    model = CNN()\n",
    "    return model\n",
    "\n",
    "def build_transformer(hidden_dim, dropout, nheads, dim_feedforward, enc_layers, dec_layers):\n",
    "    return Transformer(\n",
    "        d_model=hidden_dim,\n",
    "        dropout=dropout,\n",
    "        nhead=nheads,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        num_encoder_layers=enc_layers,\n",
    "        num_decoder_layers=dec_layers\n",
    "    )\n",
    "\n",
    "'''\n",
    "_______________________\n",
    "Create the model with the current params\n",
    "_______________________\n",
    "'''\n",
    "\n",
    "def build_pretrain_model_hic(device, bins=200, nheads=4, hidden_dim=512, embed_dim=256, dim_feedforward=1024, enc_layers=1, dec_layers=2, dropout=0.2):\n",
    "    backbone = build_backbone()\n",
    "    transformer = build_transformer(hidden_dim, dropout, nheads, dim_feedforward, enc_layers, dec_layers)\n",
    "    pretrain_model = Tranmodel(\n",
    "            backbone=backbone,\n",
    "            transfomer=transformer\n",
    "        )\n",
    "\n",
    "    model_dict = pretrain_model.state_dict()\n",
    "    pretrain_dict = torch.load(\"Parameter File\", map_location='cpu')\n",
    "    pretrain_dict = {k: v for k, v in pretrain_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrain_dict)\n",
    "    pretrain_model.load_state_dict(model_dict)\n",
    "    return pretrain_model\n",
    "\n",
    "'''\n",
    "_______________________\n",
    "Create the embeddings\n",
    "_______________________\n",
    "'''\n",
    "\n",
    "def create_embedding(start_pos, end_pos, curr_chr='Your interested chromosome', bins=200, nheads=4, hidden_dim=512, embed_dim=256, dim_feedforward=1024, enc_layers=1, dec_layers=2, dropout=0.2): ### curr_chr is the input chromosome index because you would fetch the genomic info from this chromosome. e.g. '15'\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    cl='GM12878'\n",
    "    dnase_data, ref_data = prepare_train_data(cl,curr_chr)\n",
    "\n",
    "    ### Create the input\n",
    "    input_x = []\n",
    "    input_x.append(torch.cat((ref_data[curr_chr][start_pos:end_pos],dnase_data[curr_chr][start_pos:end_pos]),dim=1))\n",
    "    input_x = torch.stack(input_x)\n",
    "\n",
    "    input_x = input_x.float().to(device)\n",
    "\n",
    "    model= build_pretrain_model_hic(device)\n",
    "    model.cuda()\n",
    "\n",
    "    output = model(input_x)\n",
    "    torch.save(output, \"chr_%d_%d.pt\"%(start_pos, end_pos))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc9514f-f3d0-4ce4-bdae-1a4571b3d1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/slurm_tmp/24555040.0.0/ipykernel_1925524/4205145865.py:61: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  dnase = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "cell_type = 'GM12878'\n",
    "dnase_data, ref_data = prepare_train_data(cell_type,'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ee04cd-c964-4121-8f60-ce6bb6fdf5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dnase_data['1']!=0).any(-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c478a52-ac43-4d48-be60-dec0c674c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     9,     10,     15, ..., 248944, 248945, 248946]),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((dnase_data['1']!=0).any(-1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a59e58cd-baec-437b-9312-0c6f7c0bc0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnase_data['1'][784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0220a4ed-9601-410b-9d79-b70a06e90700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_pickle(\"../../data/raw_embeddings/my_dict.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63195b85-79af-46ea-b542-9b17bd059bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 780, 2080])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeb91b5f-a0f8-4bef-adf7-5e868cce8c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248956, 4, 1600])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbad3382-9521-4df9-af23-a80a56a91abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0], dtype=torch.int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data['1'][0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3e9257e-8044-44ef-8bcb-43d64a38b65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1], dtype=torch.int8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data['1'][780,:,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f8af2e7-229d-4c91-a503-2afff261872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248956, 4, 1600])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b44c28d4-0a0a-438c-ab9f-553dac39a256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248956, 1, 1600])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnase_data['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dad47a-eeb5-41ae-9bd6-f28d152d73f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
